Hibernate 对象/关系映射能力强，数据库无关性好，对于关系模型要求高的 软件，如果用 hibernate 开发可以节省很多代码，提高效率

#{}是预编译处理，${}是字符串替换。


Mybatis 在处理#{}时，会将 sql 中的#{}替换为**?号，调用 PreparedStatement 的 set** 方法来赋值； Mybatis 在处理${}时，就是把${}替换成变量的值。 使用#{}可以有效的防止 SQL 注入，提高系统安全性。



<resultMap type=”me.gacl.domain.order” id=”orderresultmap”> <!–用 id 属性来映射主键字段–> <id property=”id” column=”order_id”> <!–用 result 属性来映射非主键字段，property 为实体类属性名，column 为数据表中的属性–> <result property = “orderno” column =”order_no”/> <result property=”price” column=”order_price” /> </reslutMap>

在 Mybatis 中，

每一个 
select、insert、update、delete标签，都会被解析为一个 **MapperStatement** 对象


**Mapper 接口里的方法，是不能重载的**，因为是使用 全限名+方法名 的保存和寻 找策略。Mapper 接口的工作原理是 JDK 动态代理，**Mybatis 运行时会使用 JDK 动态代理为 Mapper 接口生成代理对象 proxy**，代理对象会拦截接口方法，转而 **执行 MapperStatement 所代表的 sql，然后将 sql 执行结果返回**。

Mybatis 使用 RowBounds

分页插件的基本原理是使用 **Mybatis 提供的插件接口**，实现自定义插件，在插件 的拦截方法内拦**截待执行的 sql**，然后**重写 sql**，根据 dialect 方言，添加对应的物 理分页语句和物理分页参数。

传递参数
#{0}代表接收的是 dao 层中的第一个参数，#{1}代表 dao 层中第二 参数，更多参数一致往后加即可

@param 注解 或 第三种：多个参数封装成 map

Mybatis 手动编写 sql


接口绑定有两种实现方式,一种是通过注解绑定，就是在接口的方法上面加上 @Select、@Update 等注解，里面包含 Sql 语句来绑定；另外一种就是通过 xml 里面写 SQL 来绑定, 在这种情况下,要指定 xml 映射文件里面的 namespace 必须 为接口的全路径名。当 Sql 语句比较简单时候,用注解绑定, 当 SQL 语句比较复杂 时候,用 xml 绑定,一般用 xml 绑定的比较多

-------------
这 种特性使得 Zookeeper 不能用于存放大量的数据，**每个节点的存放数据上限为 1M**，内存中维护了这个树状的目录结构，

ZAB 协议是为分布式协调服务 Zookeeper 专门设计的一种支持崩溃恢复的原子广 播协议

崩溃恢复和消息广播

临时节点的生命周期与客户端会话绑定，一旦客户端会话失效（客户端与 zookeeper 连接断开不一定会话失效），那么这个客户端创建的所有临时节点都 会被移除。

Zookeeper 允许客户端向服务端的某个 Znode 注册一个 Watcher 监听，当服务 端的一些指定事件触发了这个 Watcher，服务端会向指定客户端发送一个事件通 知来实现分布式的通知功能，然后客户端根据 Watcher 通知状态和事件类型做出 业务上的改变。

**Zookeeper 只能保证最终的一致性，而无法保证强一致性**

Leader 
1、**事务请求**的唯一调度和处理者，保证集群事务处理的顺序性 
2、集群内部各服务的调度者 

Follower 
1、处理客户端的非事务请求，转发事务请求给 Leader 服务器 2、参与事务请求 Proposal 的投票 
3、参与 Leader 选举投票

Zookeeper 下 Server 工作状态 服务器具有四种状态，分别是 LOOKING、FOLLOWING、LEADING、OBSERVING

1、**LOOKING**：寻找 Leader 状态。当服务器处于该状态时，它会认为当前集群中 没有 Leader，因此需要进入 Leader 选举状态。 2、FOLLOWING：跟随者状态。表明当前服务器角色是 Follower。 3、LEADING：领导者状态。表明当前服务器角色是 Leader。 4、OBSERVING：观察者状态。表明当前服务器角色是 Observer。


**选举、同步**  选举交换信息的过程、依据myid选举；

zookeeper 是如何保证事务的顺序一致性的

zxid 实际上是一个 64 位的数字，高 32 位是 epoch（时 期; 纪元; 世; 新时代）用来标识 leader 周期，如果有新的 leader 产生出来，epoch 会自增，低 32 位用来递增计数。


在分布式环境中，有些业务逻辑只需要集群中的某一台机器进行执行，leader 选举


zk 的负载均衡是可以调控，


chubby 是 google 的，完全实现 **paxos** 算法，不开源。zookeeper 是 chubby 的开源实现，使用 zab 协议，paxos 算法的变种。


zookeeper 常用的命令。 常用命令：ls get set create delete 等


ZAB 用来构建高可用的分布式数据主备系统（Zookeeper），Paxos 是用来构建 分布式一致性状态机系统。

zk 的命名服务 负载均衡 

对于第一类，我们将 zookeeper 上的一个 znode 看作是一把锁，通过 createznode 的方式来实现。所有客户端都去创建 /distribute_lock 节点，最终成功创建的那 个客户端也即拥有了这把锁。用完删除掉自己创建的 distribute_lock 节点就释放 出锁。 对于第二类， /distribute_lock 已经预先存在，所有客户端在它下面创建临时顺 序编号目录节点，和选 master 一样，编号最小的获得锁，用完删除，依次方便。

队列按照 FIFO 方式进行入队和出队操作。 第一类，在约定目录下创建临时目录节点，监听节点数目是否是我们要求的数目。 第二类，和分布式锁服务中的控制时序场景基本原理一致，入列有编号，出列按 编号。在特定的目录下创建 PERSISTENT_SEQUENTIAL 节点，创建成功时 Watcher 通知等待的队列，队列删除序列号最小的节点用以消费。此场景下 Zookeeper 的 znode 用于消息存储，znode 存储的数据就是消息队列中的消息内 容，SEQUENTIAL 序列号就是消息的编号，按序取出即可。由于创建的节点是持 久化的，所以不必担心队列消息的丢失问题




Dubbo 默认是阻塞的，可以异步调用，没有返回值的可以这么做

异步调用会返回一个 Future 对 象

推荐使用 Zookeeper 作为注册中心,推荐使用 Hessian 序列化

服务失效踢出基于 zookeeper 的临时节点原理

采用多版本开发，不影响旧版本

可以结合 zipkin 实现分布式服务追踪

Failover Cluster 失败自动切换，自动重试其它服务器（默认）

Failback Cluster 失败自动恢复，记录失败请求，定时重发

Forking Cluster 并行调用多个服务器，只要一个成功即返回

Dubbo 服务降级

可以通过 dubbo:reference 中设置 mock="return null"。mock 的值也可以修 改为 true，然后再跟接口同一个路径下实现一个 Mock 类，命名规则是 “接口 名称+Mock” 后缀。然后在 Mock 类里实现自己的降级逻辑

默认情况下，在 consumer 和 provider 的 **filter 链**中都会有 Monitorfilter。 1、MonitorFilter 向 DubboMonitor 发送数据

工厂模式、代理模式、装饰器模式、观察者模式

Dubbo 支持分布式事务吗？ 目前暂时不支持，可与通过** tcc**-transaction 框架实现

Dubbo 提供了声明式缓存，以减少用户加缓存的工作 量<dubbo:reference cache="true" />

可以用版本号（version）过渡，多个不同版本的服务注册到注册中心，版本号不 同的服务相互间不引用

Dubbo 必须依赖 JDK，其他为可选

连接服务 telnet localhost 20880 //键入回车进入 Dubbo 命令模式。 查看服务列表 dubbo>ls com.test.TestService

dubbo>ls com.test.TestService create delete query  显示服务提供的方法

Dubbo 是通过 JDK 的 ShutdownHook 来完成优雅停机的

Dubbox 是继 Dubbo 停止维护后，当当网基于 Dubbo 做的一个扩展项目，如 加了服务可** Restful **调用，更新了开源组件等

**服务调用方式 dubbo 是RPC | spring clound 提供的是REST API**


别的分布式框架吗？ 别的还有 spring 的 spring cloud，facebook 的 thrift，twitter 的 finagle 等


**倒排索引**，是通过分词策略，形成了词和文章的映射关系表，这种词典+映射表 即为倒排索引

倒排索引的底层实现是基于：FST（Finite State Transducer）数据结 构。


冷热数据分离存储，热数据（比如最近 3 天或者一周的数据），其余为冷数据。 对于冷数据不会再写入新数据，可以考虑定期 force_merge 加 shrink 压缩操作， 节省存储空间和检索效率

动态新增机器的方式可以缓解集群压力

搜索拆解为“query then fetch” 两个阶段

query 阶段的目的：定位到位置，但不取。 步骤拆解如下： 1、假设一个索引数据有 5 主+1 副本 共 10 分片，一次请求会命中（主或者副本 分片中）的一个。 2、每个分片在本地进行查询，结果返回到本地有序的优先队列中。 3、第 2）步骤的结果发送到**协调节点，协调节点产生一个全局的排序列表**。 fetch 阶段的目的：取数据。 路由节点获取所有文档，返回给客户端。


句柄、内存方面的调整

脑裂问题


Kibana 监控 Elasticsearch

**canal ->生产+mq +消费 ->过度到es  就可以加工搜索了**


Trie 的核心思想是空间换时间，利用字符串的公共前缀来降低查询时间的开销以 达到提高效率的目的。它有 3 个基本性质： 

1、根节点不包含字符，除根节点外每一个节点都只包含一个字符。 
2、从根节点到某一节点，路径上经过的字符连接起来，为该节点对应的字符串。 
3、每个节点的所有子节点包含的字符都不相同。

字典树有个特征从头开始往后比较

**思路很好**：于中文的字典树，每个节点的子节点用一个哈希表存储，这样就不用浪费太 大的空间，而且查询速度上可以保留哈希的复杂度 O(1)。

负载均衡器 通过对 key 做 hash (一致性哈希算法) 一致哈希算法的目的是不但保证每个对象只请求一个对应的服务器，而且当节点宕机，缓存服务器的更新**重新分配比例降到最低**

多核CPU上，MySQL 的 **query cache** 会遇到扩展问题（scalability issues）。在多核 CPU 上，query cache 会增加一个全局锁（**global lock**）, 由 于需要刷新更多的缓存数据，速度会变得更慢

Memcached 主要的 cache 机制是 LRU（最近最少用）算法+超时失效，内存不够用时的内存淘汰算法

**热备节点，其他节点down时自己上哈**；

**memcached 支持多线程** ，单体存储仅1M,memcached自身的内存管理决定了，默认会使用内部的slab分配器；

memcached的单个命令是完全原子的

解决集群环境下的 seesion 共享问题，共有 4 种解决方案：

1.粘性 session 粘性 session 是指 Ngnix 每次都将同一用户的所有请求转发至同一台服务器上， 即将用户与服务器绑定。 

2.服务器 session 复制 即每次 session 发生变化时，创建或者修改，就广播给所有集群中的服务器，使 所有的服务器上的 session 相同。

3.session 共享 缓存 session，使用 redis， memcached。 

4.session 持久化 将 session 存储至数据库中，像操作数据一样才做 session

------

memcached 与 redis 的区别？ cpu 支持的数据类型 内存 磁盘
1、Redis 不仅仅支持简单的 **k/v** 类型的数据，同时还提供 list，set，zset，hash 等数据结构的存储。而 memcache 只支持简单数据类型，需要客户端自己处理复 杂对象 
2、Redis 支持数据的**持久化**，可以将内存中的数据保持在磁盘中，重启的时候可 以再次加载进行使用（PS：持久化在 rdb、aof）。
3、由于 Memcache 没有持久化机制，因此宕机所有缓存数据失效。Redis 配置 为持久化，宕机重启后，将自动加载宕机时刻的数据到缓存系统中。具有更好的 **灾备机制**。
4、Memcache 可以使用 Magent 在客户端进行一致性 hash 做分布式。Redis 支 持在服务器端做分布式（PS:Twemproxy/Codis/Redis-cluster 多种分布式实现方 式）
5、Memcached 的简单限制就是键（key）和 Value 的限制。最大键长为 **250** 个 字符。可以接受的储存数据不能超过 **1MB**（可修改配置文件变大），因为这是典 型 slab 的最大值，不适合虚拟机使用。而 Redis 的 Key 长度支持到 **512k**。
6、Redis 使用的是**单线程**模型，保证了数据按顺序提交。Memcache 需要使用 cas 保证数据一致性。CAS（Check and Set）是一个确保并发一致性的机制，属 于“乐观锁”范畴；原理很简单：拿版本号，操作，对比版本号，如果一致就操 作，不一致就放弃任何操作
cpu 利用。由于 Redis 只使用单核，而 Memcached 可以使用多核，所以平均每 一个核上 Redis 在存储小数据时比 Memcached 性能更 高。而在 100k 以上的数 据中，Memcached 性能要高于 Redis 。
7、memcache **内存管理**：使用 Slab Allocation。原理相当简单，预先分配一系 列大小固定的组，然后根据数据大小选择最合适的块存储。避免了内存碎片。（缺 点：不能变长，浪费了一定空间）memcached 默认情况下下一个 slab 的最大值 为前一个的 1.25 倍。
8、redis 内存管理： Redis 通过定义一个数组来记录所有的内存分配情况， Redis 采用的是包装的 malloc/free，相较于 Memcached 的内存 管理方法来说，要简 单很多。由于 malloc 首先以链表的方式搜索已管理的内存中可用的空间分配，导致内存碎片比较多  ？

性能极高 – Redis 能读的速度是 110000 次/s,写的速度是 81000 次/s

多个操作也支持事务，即原子性，通过 MULTI 和 EXEC 指令包起来

Redis 支持五种数据类型：string（字符串），hash（哈希），list（列表）， set（集合）及 zsetsorted set：有序集合)

按 key 设置过期时间

RDB、aof持久化，rdb文件，aof文件
rdb以db文件方式，间隔一段时间持久方式，可能丢失部分数据   Redis DataBase
aof命令方式持久化，数据不丢失 ，但重启可能耗时  Append-only file

pipeline 前后没有因果关系

Redis 集群，集群的原理是什么？ 1)、Redis Sentinal 着眼于高可用，在 master 宕机时会自动将 slave 提升为 master，继续提供服务。 2)、Redis Cluster 着眼于扩展性，在单个 redis 内存不足时，使用 Cluster 进行 分片存储

Redis 支持的 Java 客户端都有哪些？官方推荐用哪个？ 答：Redisson、Jedis、lettuce 等等，官方推荐使用 **Redisson**  功能较为简单，不支持字符串操作，不支持排序、事务、管道、分区等 Redis 特性

Redis 如何设置密码及验证密码？ 设置密码：config set requirepass 123456 授权密码：auth 123456

Redis 集群没有使用一致性 hash,而是引入了哈希槽的概念，Redis 集群有 16384 个哈希槽，每个 key 通过 CRC16 校验后对 16384 取模来决定放置哪个槽， 集群的每个节点负责一部分 hash 槽。

Redis 并不能保证数据的强一致性，这意味这在实际中集群在特定的条件下可 能会丢失写操作

异步复制

Redis 集群最大节点个数是多少？ 答：16384 个

Redis 集群目前无法做数据库选择，默认在 0 数据库

Redis 事务相关的命令有哪几个？ 答：MULTI、EXEC、DISCARD、WATCH

Redis key 的过期时间和永久有效分别怎么设置？ EXPIRE及PERSIST 命令

Redis 提供 6 种数据淘汰策略

scan 指令 扫描

一般需要在时间上加一个随机值，使得过期时间分散一 些

------------------------------------
CHAR 列长度固定为创建表时声明的长度，长度值范围是 1 到 255 当 CHAR


TIMESTAMP 创建(默认CURRENT_TIMESTAMP)及更新(根据当前时间搓更新)  可配置相关属性

SHOW INDEX FROM <tablename>; 查看某表索引


UNIX_TIMESTAMP 是从 MySQL时间转换为 Unix 时间戳的命令
 
FROM_UNIXTIME 是从 Unix时间戳转换为 MySQL 时间的命令

BLOB 和 TEXT 后者排序比较不区分大小写

CURRENT_DATE（）仅显示当前年份，月份和日期

CURRDATE(), CURRTIME()- 返回当前日期或时间

NOW（） – 将当前日期和时间作为一个值返回


Thread.setDaemon(bool） 必须在start之前设置

进程是操作系统分配资源的最小单元，线程是操作系统调度的最小单元


不同的线程切换使用 CPU 发生的切换数据等就是**上下文切换**。

活锁 导致一直重复尝试

饥饿：一个或者多个线程因为种种原因无法获得所需要的资源，

excute 是void  ,submit 是有返回值 future对象


有界队列比如 ArrayBlockingQueue
maximumPoolSize 的值增加线程数量，如果增加了线程数量还是处理不过来

Math.round(11.5)的返回值是 12，Math.round(-11.5)的返回值是-11。四舍五 入的原理是在参数上加 0.5 然后进行下取整。

最外层循环前加一个标记如 A，然后用 break A;可以跳出多重循环

XML 文档定义分为 DTD 和 Schema 两种形式

Java 中，**int 类型**变量的长度是一个固定值，与平台无关，都是 **32 位**。意思就 是说，在 32 位 和 64 位 的 Java 虚拟机中，int 类型的长度是相同的。

java.lang.Runtime

**poll**() 和 remove() 都是从队列中取出一个元素，但是 poll() 在获取元素失败 的时候会返回空，但是 remove() 失败的时候会抛出异常。

Arrays.toString() 可以打印每个元素。

Java 中的 LinkedList 是双向链表

TreeMap 是使用红黑树实现的。

Comparable 接口用于定义对象的自然顺序，而 comparator 通常用于定义用户 定制的顺序。Comparable 总是只有一个，但是可以有多个 comparator 来定义 对象的顺序


byte[] bytes = new byte[10]; ByteBuffer buf = ByteBuffer.wrap(bytes);

幂等性是能够以这样的方式做两次事情的特性，即最终结果将保持不变，即好像 它只做了一次

OAuth 代表开放授权协议

RESTful API 基于 Web 的开放网络原则，为构建微服务架 构的各个组件之间的接口提供了最合理的模型

持续集成（CI）是每次团队成员提交版本控制更改时自动构建和测试代码的过程。 这鼓励开发人员通过在每个小任务完成后将更改合并到共享版本控制存储库来共 享代码和单元测试

wc 命令 - c 统计字节数 - l 统计行数 - w 统计字数

一般都是使用 & 在命令结尾来让程序自动运行。

job -l   后台任务

df -hl

env  查看环境变量

du 显示目录或文件的大小   df 显示每个<文件>所在的文件系统的信息，默认是显示所有文件系统

**compgen -c**，可以打印出所有支持的命令列表  这个命令管用

使用 linux 命令 ’disown -r ’可以将所有正在运行的进程移除

man rpm -5

spring-boot-devtools 开发防止重启

Spring boot actuator 监视器

Swagger 广泛用于可视化 API

WebSocket 消息数据交换要轻得多

Spring Cloud Bus 提供了跨多个实例刷新配置的功能。

在消息消费时，要求消息体中必须要有一个 bizId


Kafka 遵循了一种大部分 消息系统共同的传统的设计：producer 将消息推送到 broker，consumer 从 broker 拉取消息。

Pull 有个缺点是，如果 broker 没有可供消费的消息，将导致 consumer 不断在循 环中轮询，直到新消息到 t 达。为了避免这点，Kafka 有个参数可以让 consumer 阻塞知道新消息到达(当然也可以阻塞知道消息的数量达到某个特定的量这样就可 以批量发送)。

Topic 被分成了若干分区，每个分区在同一时间只被一 个 consumer 消费，consumer 可以把 offset 调成一个较老的值，去重新消 费老的消息

恢复性：加入队列中的消息仍然可以在系统恢复

顺序保证： Kafka 保证一个 Partition 内的消息的有序性

缓冲 解决生产消息和消费消息的处理速度

异步通信 用户不想也不需要立即处理消息

Kafka 持久化日志，这些日志可以被重复读取和无限期保留 ，Kafka 支持实时的流式处理

消费者如何不自动提交偏移量，由应用提交 将 auto.commit.offset 设为 false，然后在处理一批消息后 commitSync() 或者异步提交 commitAsync()

max.poll.interval.ms：增大 poll 的间隔
max.poll.records：此设置限制每次调用 poll 返回的消息数

如何控制消费的位置 kafka 使用 seek(TopicPartition, long)指定新的消费位置。用于查找服务器保留 的最早和最新的 offset 的特殊的方法也可用（seekToBeginning(Collection) 和 seekToEnd(Collection)）

Kafka 分布式的单位是 partition，同一个 partition 用一个 write ahead log 组织， 所以可以保证 FIFO 的顺序。

不消费重复数据 - >  幂等性




































