第一范式：保证数据库中的表每一列都是不可以再分的原子列
用户编号 姓名 电话 地址 这里如果需求中想统计这张用户表中的省份信息，市级信息；这里的设计就
违背了数据库设计的第一范式，因为这里的“地址”字段是可以再分的“省、市、区、
街道….”。 第二范式：在满足第 1NF 的基础上，确保表中的每列都和主键相关
班级编号 班级名称 学生编号 学生名称 上面是班级信息表与学生之间的关系，这里大家可能一眼就能看出学生名称与班级编号没有直接关系，而且如果同一个班级有多名学生，这里的班级名称会
一直冗余，所以它违背了第 2NF 范式。 第三范式：在满足第 2NF 基础上，属性不能传递依赖于主属性
班级编号 班级名称 学生编号 学生名称 还是通过这张表中来说明，这里的学生名称依赖学生编号，学生名称并不依赖主键“班级编号”，所以它违背了第 3NF，应该将两张表拆开。

数据库的分页方式
解析：这个很简单，mysql 分页使用 limit 关键字，oracle 使用 rownum 关键字，sqlserver 使用关键字 top，这里我就不逐个写例子了，面试的同学自己写一下，笔试中可能遇到。

DML(Data Manipulation Language)数据操纵语言；对数据库中的数
据进行一些简单操作，如 insert,delete,update,select 等.
DDL(Data Definition Language)数据定义语言：对数据库中的某些对象进行操
作，如 create,alter,drop,truncate,(create index)等. DCL(Data Control Language)数据控制语言， 如 commit、 rollback、grant、
invoke 等
DML 和 DDL 区别：
1.DML 主要侧重于应用级开发，程序中是可以手动控制事务的开启、提交和
回滚的。
2.DDL 主要侧重于服务端管理，不需要考虑事务操作。

mysql 的最大连接数默认是 100, 这个数值对于并发连接
很 多 的 数 据 库 应 用 是 远 远 不 够 的 ， 可 以 通 过 编 辑 编 辑 my.ini 修 改
max_connections=1000 增大连接数

in 和 not in 也要慎用，否则会导致全表扫描，对于连续的数值，能用between 就不要用 in 了

1、JDBC 连接：connection url 中加参数: autoReconnect=true 
jdbc.url=jdbc:mysql://ipaddress:3306/database?autoReconnect=true&amp;autoRe
connectForPools=true（话说只能在 mysql5 之前的版本有效，mysql5 之后的版本
我没有亲自测试）。

通过命令修改'wait_timeout'的值(需要重启 mysql 服务器)：
use mysqlname; -- 在 mysql 库下。
SHOW GLOBAL VARIABLES LIKE 'wait_timeout'; -- 查看当前值。
SET GLOBAL wait_timeout = 1814400; -- 修改(这里为 21 天单位秒)。

oracle 冷备份与热备份区别
解析：冷备份就是在数据库关闭的情况下进行备份，可以直接 COPY 文件，简单易操作；热备份是在数据库运行的情况下进行备份，必须是 archive log 模式下

union 、unilon all 作用在两张表一样的表上，都是对两表查询
的结果求并集合。union 查询出来的结果，会过滤掉重复行，并且按照默认规
则排序。union all 查询出来的结果，不会进行重复过滤，也不会进行排序。如 果确认两表中没有重复数据，建议用 union all 代替 union，union all 效率要高


因为 Enum 实现了序列化接口 Serializable，所以枚举是可以被序列化的

ii.newFixedThreadPool
创建固定大小的线程池。每次ᨀ交一个任务就创建一个线程，直到线程达到
线程池的最大大小。线程池的大小一旦达到最大值就会保持不变，如果某个线程
因为执行异常而结束，那么线程池会补充一个新线程。
iii. newCachedThreadPool
创建一个可缓存的线程池。如果线程池的大小超过了处理任务所需要的线程，
那么就会回收部分空闲（60 秒不执行任务）的线程，当任务数增加时，此线程
池又可以智能的添加新线程来处理任务。此线程池不会对线程池大小做限制，线
程池大小完全依赖于操作系统（或者说 JVM）能够创建的最大线程大小。
iv.newScheduledThreadPool
创建一个大小无限的线程池。此线程池支持定时以及周期性执行任务的需求。

同步一定是发生在多线程条件下，对共同资源不安全的访问进行控制
一种手段；异步是要求减少请求方时间的等待

栈是跟随线程的，有线程就有栈

这里主要有 bootstrap classloader、extension cassLoader、AppClassLoader 三个类的加载器

JVM 为了避免类的重复加载，引入了委托加载机制，比如 A 中定义Ｂ的引用，对于Ｂ的加载是通过委托 A 的加载器去加载

 Old 区被放满的之后，进行 fullGC

jstack 主要用于线程死
锁的监控；jmap 主要用于监控内存泄露时候对象占用的字节数；jstat 主要用于监控 jvm 的 gc 使用情况；jhat 主要用于分析 jmap 产生的 dump 并ᨀ供 web 页面查看分析结果

被浏览器禁用，但如果 Cookie 完全被禁用，Session 的会话功能也将失效

；Hibernate
的缓存有一级缓存 Session 是必须知道的；而面试人员一般想让你回答的是二级缓存 SessinFactory（通常使用的是第三方缓存），它的实现比较复杂

MyBatis 中在查询进行 select 映射的时候，返回类型可以用
resultType，也可以用 resultMap；resultType 是直接表示返回类型的(PO 类)，而resultMap 则是对外部 ResultMap 的引用(在 po.xml 中配置的映射 key-->value 关 系)，但是 resultType 跟 resultMap 不能同时存在。


BeanFactory 负责读取 bean 配置文档，管理 bean 的加载，实例化，维护 bean之间的依赖关系，负责 bean 的声明周期。
ApplicationContext 除了ᨀ供上述 BeanFactory 所能ᨀ供的功能之外，还ᨀ供了更完整的框架功能：国际化支持、资源访问、事件传递等

1、String 类是一个不可变类，被 final 修改的类不能被继承，这样ᨀ高了String 类使用的安全性。
2、String 类的主要变量 value[]都被设计成 private final 的，这样在多线程时，对 String对象的访问是可以保证安全。 
3、JVM 对 final 修饰的类进行了编译优化，设计成 final，JVM 不用对相关方法在虚函数表中查询，直接定位到 String 类的相关方法调用，ᨀ高了执行效率

Class.forName 和 ClassLoader 都是用来装载类的，对于类的装载一般为分
三个阶段加载、链接、编译，它们装载类的方式是有区别。 首先看一下 Class.forName（..），forName（..）方法有一个重载方法 forName(className, 
boolean,ClassLoader)，它有三个参数，第一个参数是类的包路径，第二个参数是 boolean
类型，为 true 地表示 Loading 时会进行初始化，第三个就是指定一个加载器；当你调用
class.forName(..)时，默认调用的是有三个参数的重载方法，第二个参数默认传入 true,第
三个参数默认使用的是当前类加载时用的加载器。
ClassLoader.loadClass()也有一个重载方法，从源码中可以看出它默认调的是它的重载
方法 loadClass(name, false)，当第二参数为 false 时，说明类加载时不会被链接。这也是两
者之间最大区别，前者在加载的时候已经初始化，后者在加载的时候还没有链接。如果
你需要在加载时初始化一些东西，就要用 Class.forName 了，比如我们常用的驱动加载

强引用（StongReference）、软引用（SoftReference）、弱引用（WeakReference）、虚引用
（PhantomReference），它们的各自特点及使用领域。 强引用：代码中最常用看到的 Object o = new Object();这里就是强引用，只要引用在，
GC 就不回收它，如果 JVM 内存空间不足会抛出 OutOfMemoryError。 软引用：通常用᧿述一些有用但不是必需的对象，如果 JVM 内存不足时，会被 GC，
通常被用来作为一些缓存模块的设计，而且不容易 OOM。 弱引用：比软引用还低级别的引用，软引用一般是内存不足时回收，而弱引用只要
被 GC 扫᧿线程发现就会回收掉，即便是 JVM 内存还充足的情况下。 虚引用：如其名，虚无般的存在，完全不会影响对象的生命周期，如果一个对象仅 持有虚引用，就如同没有引用一样，可能随时被回收掉，一般会与强用队列关联使用，一般只用于对象回收的事件传递。

进程是资源分配的基本单位，线程是处理机调度的基本单位，所有的线程共享其
所属进程的所有资源与代码。

foreach 遍历的字节码可以看出，底层实现也是用迭代器来实现的；所以我们可以肯定 foreach 只是 JVM 编译器的一个语法糖而已。

switch 中的字符串变成了字符串的 hashCode，也就是一个 int 型整数。

在 AQS 中维护着一个双向队列和 volatile 变量的state 值

表12­15 调优参数 配置参数 缺省值 调优场景 num.recovery.threads.per.data.dir 10 在Kafka启动过程中，数据量较大情况下，可调大此参数，可以提升启动 速度。 background.threads 10 Broker后台任务处理的线程数目。数据量较大的情况下，可适当调大此 参数，以提升Broker处理能力。 num.replica.fetchers 1 副本向Leader请求同步数据的线程数，增大这个数值会增加副本的I/O并 发度。 num.io.threads 8 Broker用来处理磁盘I/O的线程数目，这个线程数目建议至少等于硬盘的
个数。 KAFKA_HEAP_OPTS -Xmx6G Kafka JVM堆内存设置。当Broker上数据量较大时，应适当调整堆内存 大小。

io流中 使用装饰器模式

CMS收集器 是老年并发标记清除收集算法

单个cookie保存的数据不超过4k

get 和post  请求
get被强制服务器支持？
浏览器对url的**长度有限制**、get请求发**送数据小**
get请求**不安全**，post比get更安全
get请求是幂等的？
post请求**不能被缓存**

udp是无连接的，即发送数据前不需要建立连接即三次握手
udp支持一对一、一对多、多对已和多对多的交互通信
udp是面向报文的、没有拥塞控制
udp首部开销小，只有8个字节
tcp每条连接只能两个端点，连接只能是点对点的
tcp可靠交互服务
tcp是全双工通信
tcp面向字节流
tcp首部最低20个字节
tcp中有华东窗口的概念、控制流速、拥塞的控制


dns缓存、本地host文件、服务商dns解析

show  VARIABLES like 'datadir'  可查看mysql的数据目录文件
/etc/inint.d/mysqld start
ls -l /data/mysql/cxwms
可看到frm文件及ibd文件
innodb存储引擎 每张表聚集的方式 按主键的顺序进行存放？

innodb存储引擎是linux上默认的存储引擎

MyIsAm存储引擎 不支持事务、是windows系统上默认的方式，myd、myi组成，只缓存索引文件

archive存储引擎 、federated存储引擎、maria存储引擎等，拥有多种存储引擎，某些引擎支持全文检索

show ENGINES; -- 查看支持的存储引擎特性

MEMORY	YES	Hash based, stored in memory, useful for temporary tables	NO	NO	NO
CSV	YES	CSV storage engine	NO	NO	NO
MRG_MYISAM	YES	Collection of identical MyISAM tables	NO	NO	NO
BLACKHOLE	YES	/dev/null storage engine (anything you write to it disappears)	NO	NO	NO
InnoDB	DEFAULT	Supports transactions, row-level locking, and foreign keys	YES	YES	YES
PERFORMANCE_SCHEMA	YES	Performance Schema	NO	NO	NO
ARCHIVE	YES	Archive storage engine	NO	NO	NO
MyISAM	YES	MyISAM storage engine	NO	NO	NO
FEDERATED	NO	Federated MySQL storage engine			

inodb有四个线程：master thread ,io thread ，purge thread(事务提交后，回收已分配的undo页；4个线程) ，page cleaner thread 为 刷新脏页线程 目的减轻master thread线程压力；

show  VARIABLES  like  'innodb_version' ; -- 5.7.24

show engine innodb  status ;-- 看到一个 insert buffer thread ,一个log thread ,4个读线程，4个写线程
Per second averages calculated from the last 2 seconds


show VARIABLES like 'innodb_buffer_pool_size';

innodb 缓冲池内存数据对象-> 重做日志缓冲、额外内存池、数据页、索引页、插入缓冲、自适应哈希索引、锁信息、数据字典信息

LRU 最近最少使用的，淘汰算法；innodb存储引擎，缓冲池页的大小为16k

show  VARIABLES like 'innodb_old_blocks_pct' ; -- midpoint位置 新读取页插入的位置
默认37%位置 ，midpoint位置 之后称为old列表 ,之前的称为new 列表 活跃热点数据；


select table_name,space,page_number,page_type   
from  information_schema.innodb_buffer_page_lru
where oldest_modification >0 ;   -- 脏页

redo log buffer  重做日志缓冲、缓冲大小16M 每秒钟将重做日志缓冲刷新到日志文件
（每秒或每事务提交或重做日志缓冲池剩余空间小于1/2时）刷到盘的时机

额外的内存池

事务提交时，先写重做日志，再修改页。宕机时，先重做日志恢复。这就是acid的d持久性保证；
checkpoint检查点 大多数据库都有这个功能，缩短数据库恢复时间，缓冲池不够用时，将脏页刷到磁盘，重做日志不可用时，刷新脏页。

show  VARIABLES  like  'innodb_max_dirty_pages_pct';-- 脏页超过缓冲池75%则强制checkpoint刷部分脏页到盘


innodb存储引擎的核心操作大部分都集中在master thread后台线程中，能观察参数哈

BACKGROUND THREAD 能参考各参数值

顺序读，随机读 概念
B+树的特性决定了辅助索引插入的离散性
insert buffer插入缓冲 对于辅助索引帮助大,


show VARIABLES  like 'innodb_use_native_aio'; -- 核查aio是否开启 需要操作系统支持


错误日志文件、二进制日志文件、慢查询日志文件、查询日志文件等

show  VARIABLES like 'log_error' ; -- 查看错误日志文件的位置

show  VARIABLES like  'log_queries_not_using_indexes'; -- 未使用索引记录到慢查询中

SHOW VARIABLES LIKE 'general_log%' ; --  查询日志是否开启 及存储位置
--启用日志
SET GLOBAL general_log = 'ON';

1.查找错误日志文件路径
show variables like 'log_error';

慢查询日志文件路径
SHOW VARIABLES LIKE 'slow_query_log%' ;
show variables like  'slow_query_log_file';

可tail 某日志文件观看哈

二进制日志文件只记录操作更新的，操作未更新的也会被记录，不记录select查询及show

show MASTER  STATUS ; -- 查看二进制日志
show binlog events in 'mysqld.000008' ;-- 查看具体某二进制日志文件中数据

/mysqladmin shutdown -uroot -p  停止mysql
/etc/init.d/mysqld start  启动 mysql

tail -n20 error.log

Linux系统下是编辑/etc/my.cnf

5.7.24 开启慢查询
slow_query_log=ON
slow_query_log_file=/data/mysql/mysql-slow.log
long_query_time=1
log-bin=/data/mysql/mysql-bin.log
server-id=123454  #这个是关键否则报错    不同版本间有差异注意 之前版本可能没有这个配置项

service mysqld restart

./mysqladmin shutdown -uroot -p


show MASTER  STATUS ;
show BINLOG  EVENTS  in 'mysql-bin.000002' ;

/usr/local/mysql/bin/mysqlbinlog -vv  --start-position=601 /data/mysql/mysql-bin.000002     --注意参数  -vv能显示具体的信息哈

重做日志与二进制日志的区别

4.1  记录的范围不同：二进制日志会记录MySQL的所有存储引擎的日志记录（包括InnoDB、MyISAM等)，

而InnoDB存储引擎的重做日志只会记录其本身的事务日志。

4.2 记录的内容不同：二进制日志文件记录的格式可以为STATEMENT或者ROW也可以是MIXED，其记录的都是关于一个事务的具体操作内容。

InnoDB存储引擎的重做日志文件记录的关于每个页的更改的物理情况。

4.3 写入的时间也不同：二进制日志文件是在事务提交前进行记录的，而在事务进行的过程中，不断有重做日志条目被写入到重做日志文件中。

聚集索引不是物理上的连续，而是逻辑上的连续，页按照双向链表、页中记录按照双向链表，叶子节点包含行记录；

非聚集索引，叶子节点不包含行记录，但包含了定位主键

脏读 事务间 ，读到另一事务未提交的数据；
不可重复读：由于别的事务出现，一个事务**两次**读到的数据不一致

页锁介于 行锁、表锁之间，比如1000行为个页锁

重做日志用来实现事务的持久性，即事务acid中的d ;
undo操纵就是事务回滚操作，uodo log是个链表，大家共用的；

mysql支持XA  分布式事务

mysql > load data  infile '/home/mysql/a.txt' into table a ;
mysqlimport --use-threads=2 test /home/a.txt /home/b.txt  命令方式导入数据

mysqlbinlog  mysql-bin.00002 |mysql -uroot -psfsfsf  --还可指定开始点结束点

mysql -uroot -p -e ""source /tmp/statements.sql"   --也可这样导入数据

xtrabackup 在线备份工具、开源的 可支持增量备份

快照备份，也是在线的

show  master status; --显示主的状态
show  slave status; --显示从的状态

master  slave  binglog | relay log 主从复制原理

缓冲池命中率不应小于99%

mysql --help | grep my.cnf

show global status like  'innodb%read%' 


Innodb_buffer_pool_read_ahead_rnd	0
Innodb_buffer_pool_read_ahead	0
Innodb_buffer_pool_read_ahead_evicted	0
Innodb_buffer_pool_read_requests	125285
Innodb_buffer_pool_reads	556
Innodb_data_pending_reads	0
Innodb_data_read	9179648
Innodb_data_reads	603
Innodb_pages_read	555
Innodb_rows_read	107863

缓冲池命中率=
Innodb_buffer_pool_read_requests/(Innodb_buffer_pool_read_requests + Innodb_buffer_pool_read_ahead + Innodb_buffer_pool_reads)   

>99 %

125285 /125285 + 556 125841

innodb通过force log at commit机制实现事务的持久性，即在事务提交的时候，必须先将该事务的所有事务日志写入到磁盘上的 redo log file 和 undo log file 中，进行持久化

“追加写”是指binlog文件写到一定大小后会切换到下一个，并不会覆盖以前的日志 binlog可以作为恢复数据使用，主从复制搭建，

redo log作为异常宕机或者介质故障后的数据恢复使用


sql语句的执行流程
      首先要清楚redo log和binlog两个日志模块
      1、redo log（InnoDB特有的日志模块） 重做日志文件，用于记录事务操作的变化，记录修改后的值，不管事务是否提交。保证数据的完整性。其中redo log是固定大小的，是从头开始写，写到末尾在从头开始。同时会有两个指针，一个记录写入的位置，一个标记，当前擦除的位置，不断的循环。整个过程称为crash-safe。即时数据库异常，也会有记录
      2、binlog 归档日志文件，用于记录对mysql数据库执行更改的所有操作。binlog是追加写，不会覆盖之前的。
      接下来介绍一下mysql更新一条语句的流程。
     update tb_area SET area_name = "beijing" WHERE area_id = 1
    1） 首先执行器通过id查到这条记录（搜索树或者查找数据页） ，并加载到内存中。
    2）然后对这条记录的area_name调用引擎写入接口，进行修改。
    3）修改内存中的值，同时更新redolog告知执行器完成写入（状态置为prepare），可以提交事务，执行器将这条操作记录记录在binlog，写入磁盘
    4）完成上述一系列的操作，执行器调用事务提交接口（redolog状态置为commit），完成更新操作。

    注意：Mysql的redolog模块写入拆成2步走，prepare和commit，称为两阶段提交。 整个过程为1、redolog的prepare状态 2、binlog的写入 3、redolog的commit状态，保证Mysql的可靠性。

去掉blob等 ，前缀同时换掉

https://raw.githubusercontent.com/xck503c/Collation/ccfc309b97260ad5869811ccf86d922e3c3edcf3/E-book/pdf/%E9%AB%98%E6%80%A7%E8%83%BDmysql%E7%AC%AC%E4%B8%89%E7%89%88%20%E6%B8%85%E6%99%B0%E7%89%88.pdf

mysql 默认自动提交，除非显示开始事务
可设置mysql的事务级别 默认 可重复度REPEATABLE-READ

mvcc版本的号创建时间、行的过期时间(或删除时间)
mvcc只在repeatable read、read commit两个隔离级别工作下工作。

blob 二进制类型，没有排序规则或字符集，Text类型有字符集和排序规则。

mysql  不能将blob和text系列全部长度的字符串进行索引，也不能使用这些索引消除排序。

聚簇索引的每个叶子节点包含主键值、事务id、用于事务、回滚指针以及剩余列；

页分裂 ，向聚簇索引插入无序的主键值

当页中删除的记录达到MERGE_THRESHOLD（默认页体积的50%），InnoDB会开始寻找最靠近的页（前或后）看看是否可以将两个页合并以优化空间使用

show  full  PROCESSLIST ; -- 当前线程状态

union 用到了临时表

Innodb 不能在不访问主键的情况下排他锁定行，因为行的版本信息保存在主键中；

count() 统计的列不能为空，count(*) 为统计所有的行

分组结果为默认按照文件排序

分区表 数据太大，b+树也搞不定，此时考虑分区表

视图执行查询会生成临时表

vim  /etc/profile

source  /etc/profile  ; which mysqld  查找可执行文件的路径

max_connections 默认为100 此值需要调整  可my.cnf 内加入哈
show  VARIABLES  like 'Max_%' ;

thread_cache_size  此值需要调整

set global expire_logs_days=7;

mysql> flush logs;

-- 可以手动清理 
purge binary logs to 'bin.000055'; 将bin.000055之前的binlog清掉:

mysql>purge binary logs before '2017-05-01 13:09:51';将指定时间之前的binlog清掉:

配置文件my.cnf中更改也是同样的效果，例如你将值设置成 expire_logs_days= 199

mysqladmin  shutdown -uroot -p  停机


mysqld --defaults-file=/etc/my.cnf &
mysqld_safe --defaults-file=/etc/my.cnf --user=mysql &


systemctl start mysql.service   centos7后的启动命令
systemctl stop mysql.service

随机io从缓存中受益多

不同的磁盘类型，配置的策略可能不同哈

调整端口 范围 cat /proc/sys/net/ipv4/ip_local_port_range
echo 1024 65535 > /proc/sys/net/ipv4/ip_local_port_range

cat /proc/sys/net/ipv4/tcp_max_syn_backlog  连接进入队列
调整 echo 4096  > /proc/sys/net/ipv4/tcp_max_syn_backlog

cat /proc/sys/net/ipv4/tcp_fin_timeout  默认保持1分钟
echo  20  > /proc/sys/net/ipv4/tcp_fin_timeout  可处理大量的连接

文件系统也有性能上的原因

cat /sys/block/vda/queue/scheduler 查看io调度算法

cfq公平调度
noop：电梯式调度，饿死读满足写
deadline：截至时间策略，`数据库类型最好的选择`
anticipatory：和deadline一样，只是最后一次读操作后要等待6毫秒。合并多次写为一次写，适合于文件服务器，对数据库服务器表现很差。

将磁盘调度策略改为deadline
echo deadline > /sys/block/vda/queue/scheduler

增加系统资源限制（/etc/security/limit.conf）
打开文件数量的限制，加到/etc/security/limit.conf末尾即可：
	* soft nofile 65535
	* hard nofile 65535


内核相关参数（/etc/sysctl.conf）
网络性能设置

端口监听队列：net.core.somaxconn=65535 接受数据的速率：net.core.netdev_max_backlog=65535 未获得连接的请求和保存在内存中的数量，超过时会被丢弃：net.ipv4.tcp_max_sync_backlog=65535

上述三个应该同时调大
tcp连接处理等待时间：net.ipv4.tcp_fin_timeout=10
net.ipv4.tcp_tw_reuse=1
net.ipv4.tcp_tw_recycle=1
上述三个主要加快网络连接的回收。
net.core.wmem_default=87380
net.core.wmem_max=16777216
net.core.rmem_default=87380
net.core.rmem_max=16777216
缓冲区接受和发送数据大小的最大值和默认值
探测的时间间隔（s）: net.ipv4.tcp_keepalive_time=120
消息重发时的时间间隔（s）: net.ipv4.tcp_keepalive_intvl=30
tcp连接超时前最多发送几次: net.ipv4.tcp_keepalive_probes=3
内存 kernel.shmmax = 4292967295
这个参数应该设置得足够大，以便于在一个共享内存段中容纳下整个Innodb缓冲池的大小
这个值的大小对于64位linux系统，可以取内存最大值-1byte，建议大于物理内存的一半。一般大于Innodb缓冲池的大小即可。
vm.swappiness = 0 ：当内存不足时会对系统性能产生比较大的影响。

Linux系统内存交换区（swap）：

vm.swapppiness = 0

	当系统内存不足时会将一些虚拟内存写入磁盘交换区（swap）中。

	由于使用swap会对mysql性能产生灾难性的影响。因此对mysql服务器是否使用swap分区存在一些争议。

	如果禁用swap分区也会带来一些影响：
降低操作系统的性能
容易造成内存溢出、崩溃或者被操作系统kill掉
	就上述影响而言，保留swap分区还是必要。

vm.swapppiness是告诉操作系统，除非内存完全满了，否则不使用swap。
增加系统资源限制（/etc/security/limit.conf）
打开文件数量的限制，加到/etc/security/limit.conf末尾即可：
	* soft nofile 65535
	* hard nofile 65535
*表示对所有用户有效
soft表示当前系统生效的配置
hard表示系统中能设置的最大值
nofile表示所限制的资源是打开文件的最大数量
65535限制的数量


-----------------
iostat  有些参数 可看看
iostat -dx 5  可观察 %util 参数

vmstat 可观察cpu、内存、磁盘、进程、队列等 可参考哈
观察cs上下文切换除非超过10万否则不用关心
观察 非中断休眠b及wa 高时得看看io情况
swpd 高再看看si so 高 则内存交换严重

主从复制，整个过程应该清楚如何交互的
1）主库上创建复制账号
2）主库、从库配置 (设置服务器server-id,注意各日志文件的配置)
3）通知备库连接到主库(开启连接点)
4）从库开启复制

注意：中间可用观察命令观察 show master status; show slave status;


mysqlbinlog 会打印偏移量

主从配置设置完后要注意两点：

1，首先在主从没有生效的时候，要保持两台服务器数据库表相同，数据相同

master主机上执行：
/usr/local/mysql/bin/mysqldump -uroot -p --all-databases >/root/all_database.sql

slave从库上执行：
/usr/local/mysql/bin/mysql -uroot -p <all_database.sql

如此两步骤，主库和从库数据会追加相平，保持同步！再此过程中，若主库存在业务，并发较高，在同步的时候要先锁表，让其不要有修改！
等待主从数据追平，主从同步后在打开锁！


show  master  logs ;
show  BINLOG  EVENTS in 'mysql-bin.000004' ;

主库上创建复制账号
mysql>grant replication slave,replication client on *.*
      to rep1@'192.168.0.%' identified by  'p4ssword' ;

mysql>GRANT REPLICATION SLAVE, REPLICATION CLIENT ON *.* TO slave@'192.168.1.%'IDENTIFIED BY '123456';

mysql>reset slave all；
mysql>change master to master_host='server1',
      master_user='rep1',
      master_password='p4ssword',
      master_log_file='mysql-bin.00002',
      master_log_pos=0 ;

mysql>change master to master_host='192.168.1.34',master_user='slave',master_password='123456', master_log_file='mysql-bin.000001',master_log_pos=0;  --这是从库上做的事情


复制是可拓扑的 log_slave_updates开启则备份库是可再备份到其他的

mysql-bin.index 服务器开始二进制时
mysql-relay-bin.index 中继日志的索引，同上类似
master.info 保存备库连接到主库所需信息

主库:
#binlog-do-db=db_name  #binlog日志只记录指定库的更新
#binlog-ignore-db=db_name   #binlog日志不记录指定库的更新
sync_binlog=1

备份库：
log_bin=/sdf/fgh/mysql-bin
relay_log=/sdf/sdf/relay-bin

#设置要进行或不要进行主从复制的数据库名
#replicate-do-db=db_name
#replicate-ignore-db=mysql,information_schema  忽略同步的库

skip_slave_start  防止崩溃后自动启动
read_only



mysql>start slave ;从库开始复制命令
mysql>show slave status;命令检查
如果出现：
Slave_IO_Running: Yes
Slave_SQL_Running: Yes
以上两项都为Yes，那说明没问题了

Lock Tables....READ不会阻塞其他线程对表数据的读取，会阻塞其他线程对数据变更
Lock Tables....WRITE会阻塞其他线程对数据读和写
Lock Tables....READ不允许对表进行更新操作(新增、删除也不行)，并且不允许访问未被锁住的表
Lock Tables....WRITE允许对被锁住的表进行增删改查，但不允许对其他表进行访问

FLUSH TABLES WITH READ LOCK; -- 全局锁
unlock Tables 解锁
-----
批量分配数字id，用完再申请
分布式：分片、负载，故障问题

虚拟IP，冗余、主备等

gzip -c /backup/mydb/mytable.myd > mytable.myd.gz    //创建压缩文件
scp mytable.myd.gz root@server2:/var/lib/mysql/mydb/  //拷贝的文件

gzip -c /backup/mydb/mytable.myd | ssh root@server2  "gunzip -c  -> /var/lib/mysql/mydb/mytable.myd"

nc命令注意关注下

using index 使用覆盖索引
using where 暗示查询受益不同的索引
using temporary 查询结果排序时会使用一个临时表
using filesort 对结果使用一个外部索引排序

------------------

查看命令 show full processlist / show processlist
https://dev.mysql.com/doc/refman/5.7/en/general-thread-states.html (状态全集)

Sleep
线程正在等待客户端发送数据
Query
连接线程正在执行查询
Locked
线程正在等待表锁的释放
Sorting result
线程正在对结果进行排序
Sending data
向请求端返回数据

可通过kill {id} 的方式进行连接的杀掉

SHOW STATUS LIKE 'Qcache%'; --能看到是否用到查询缓存
“Qcache_free_blocks”：Query Cache 中目前还有多少剩余的blocks。如果该值显示较大，则说明Query Cache 中的内存碎片较多了，可能需要寻找合适的机会进行整理。
● “Qcache_free_memory”：Query Cache 中目前剩余的内存大小。通过这个参数我们可以较为准确的观察出当前系统中的Query Cache 内存大小是否足够，是需要增加还是过多了；
● “Qcache_hits”：多少次命中。通过这个参数我们可以查看到Query Cache 的基本效果；
● “Qcache_inserts”：多少次未命中然后插入。通过“Qcache_hits”和“Qcache_inserts”两个参数我们就可以算出Query Cache 的命中率了：
Query Cache 命中率= Qcache_hits / ( Qcache_hits + Qcache_inserts )；
● “Qcache_lowmem_prunes”：多少条Query 因为内存不足而被清除出Query Cache。通过“Qcache_lowmem_prunes”和“Qcache_free_memory”相互结合，能够更清楚的了解到我们系统中Query Cache 的内存大小是否真的足够，是否非常频繁的出现因为内存不足而有Query 被换出
● “Qcache_not_cached”：因为query_cache_type 的设置或者不能被cache 的Query 的数量；
● “Qcache_queries_in_cache”：当前Query Cache 中cache 的Query 数量；
● “Qcache_total_blocks”：当前Query Cache 中的block 数量；

----------------------------------------
配置， 配置文件中 query_cache_type=1 则开启了缓存功能 否则不会有命中率的说法

是否启用mysql查询缓存，可以通过2个参数：query_cache_type和query_cache_size，其中任何一个参数设置为0都意味着关闭查询缓存功能。

query_cache_type 值域为：

0(OFF)：关闭 Query Cache 功能，任何情况下都不会使用 Query Cache;

1(ON)： 启用查询缓存，只要符合查询缓存的要求，客户端的查询语句和记录集斗可以 缓存起来，共其他客户端使用；

2(DEMAND):  启用查询缓存，只要查询语句中添加了参数：sql_cache，且符合查询缓存的要求，客户端的查询语句和记录集，则可以缓存起来，共其他客户端使用； select sql_cache

query_cache_size 允许设置query_cache_size的值最小为40K，对于最大值则可以几乎认为无限制，实际生产环境的应用经验告诉我们，该值并不是越大， 查询缓存的命中率就越高，也不是对服务器负载下降贡献大，反而可能抵消其带来的好处，甚至增加服务器的负载，至于该如何设置，下面的章节讲述，推荐设置 为：64M；建议设置不要超过256MB

 

缓存选项的说明：

用show global status like 'QCache%';查看

Qcache_free_blocks：目前还处于空闲状态的 Query Cache 中内存 Block 数目
Qcache_free_memory：目前还处于空闲状态的 Query Cache 内存总量
Qcache_hits：Query Cache 命中次数
Qcache_inserts：向 Query Cache 中插入新的 Query Cache 的次数，也就是没有命中的次数
Qcache_lowmem_prunes：当 Query Cache 内存容量不够，需要从中删除老的 Query Cache 以给新的 Cache 对象使用的次数
Qcache_not_cached：没有被 Cache 的 SQL 数，包括无法被 Cache 的 SQL 以及由于 query_cache_type 设置的不会被 Cache 的 SQL
Qcache_queries_in_cache：目前在 Query Cache 中的 SQL 数量
Qcache_total_blocks：Query Cache 中总的 Block 数量
内存碎片的产生。当一块分配的内存没有完全使用时，MySQL会把这块内存Trim掉，把没有使用的那部分归还以重 复利用。比如，第一次分配4KB,只用了3KB，剩1KB，第二次连续操作，分配4KB，用了2KB，剩2KB，这两次连续操作共剩下的 1KB+2KB=3KB，不足以做个一个内存单元分配， 这时候，内存碎片便产生了。使用flush query cache，可以消除碎片

下面是命中率和内存使用率的一些算法
      query_cache_min_res_unit的估计值：(query_cache_size - Qcache_free_memory) / Qcache_queries_in_cache

      查询缓存命中率 ≈ (Qcache_hits – Qcache_inserts) / Qcache_hits * 100%

      查询缓存内存使用率 ≈ (query_cache_size – Qcache_free_memory) / query_cache_size * 100%

InnoDB存储引擎的缓冲池

     通常InnoDB存储引擎缓冲池的命中不应该小于99%。

参数说明：
Innodb_buffer_pool_reads: 表示从物理磁盘读取页的次数

Innodb_buffer_pool_read_ahead: 预读的次数

Innodb_buffer_pool_read_ahead_evicted: 预读的页，但是没有读取就从缓冲池中被替换的页的数量，一般用来判断预读的效率

Innodb_buffer_pool_read_requests: 从缓冲池中读取页的次数

Innodb_data_read: 总共读入的字节数

Innodb_data_reads: 发起读取请求的次数，每次读取可能需要读取多个页

-- --------------------------
不会缓存的情况

1.当查询语句中有一些不确定的数据时，则不会被缓存。如包含函数NOW()，CURRENT_DATE()等类似的函数，或者用户自定义的函数，存储函数，用户变量等都不会被缓存。
2.当查询的结果大于query_cache_limit设置的值时，结果不会被缓存。
3.对于InnoDB引擎来说，当一个语句在事务中修改了某个表，那么在这个事务提交之前，所有与这个表相关的查询都无法被缓存。因此长时间执行事务，会大大降低缓存命中率。
4.查询的表是系统表
5.查询语句不涉及到表

为什么mysql默认关闭了缓存开启

1.在查询之前必须先检查是否命中缓存,浪费计算资源。
2.如果这个查询可以被缓存，那么执行完成后，MySQL发现查询缓存中没有这个查询，则会将结果存入查询缓存，这会带来额外的系统消耗。
3.针对表进行写入或更新数据时，将对应表的所有缓存都设置失效。
4.如果查询缓存很大或者碎片很多时，这个操作可能带来很大的系统消耗。

缓存适用业务场景
以读为主的业务，数据生成之后就不常改变的业务
比如门户类、新闻类、报表类、论坛类等

IN的优化

先进行排序，再采用二分查找的方式

type
访问类型，sql查询优化中一个很重要的指标，结果值从好到坏依次是:
system > const > eq_ref > ref > range > index > ALL

system:表只有一行记录(等于系统表)，const类型的特例，基本不会出现，可以忽略不计。
const:表示通过索引一次就找到了，const用于比较primary key或者unique索引。
eq_ref:唯一索引扫描，对于每个索引键，表中只有一条记录与之匹配。常见于主键或唯一索引扫描。
ref:非唯一性索引扫描，返回匹配某个单独值的所有行，本质是也是一种索引访问。
range:只检索给定范围的行，使用一个索引来选择行。
index:Full Index Scan，索引全表扫描，把索引从头到尾扫一遍。
ALL:Full Table Scan，遍历全表以找到匹配的行。

---------
rows
根据表统计信息或者索引选用情况，大致估算出找到所需的记录所需要读取的行数

filtered
表示返回结果的行数占需读取行数的百分比，filtered的值越大越好

Extra
十分重要的额外信息

1.Using filesort : mysql对数据使用一个外部的文件内容进行了排序，而不是按照表内的索引进行排序读取。
2.Using temporary: 使用临时表保存中间结果，也就是说mysql在对查询结果排序时使用了临时表，常见于order by 或 group by。
3.Using index:表示相应的select操作中使用了覆盖索引(Covering Index)，避免了访问表的数据行，效率高。
4.Using where : 使用了where过滤条件。
5.select tables optimized away: 基于索引优化MIN/MAX操作或者MyISAM存储引擎优化COUNT(*)操作，不必等到执行阶段在进行计算，查询执行计划生成的阶段即可完成优化。

 

